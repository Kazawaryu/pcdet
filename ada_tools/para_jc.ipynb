{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import open3d\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "# import demo as demo\n",
    "\n",
    "from pcdet.config import cfg, cfg_from_yaml_file\n",
    "from pcdet.datasets import DatasetTemplate\n",
    "from pcdet.models import build_network, load_data_to_gpu\n",
    "from pcdet.utils import common_utils\n",
    "\n",
    "\n",
    "# 3 tool class, PillarVFE, PFNLayer, PointPillarScatter\n",
    "from pcdet.models.backbones_3d.vfe import pillar_vfe as VFE\n",
    "from pcdet.models.backbones_2d.map_to_bev import pointpillar_scatter as Scatter\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "torch.cuda.set_device(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-08 08:38:19,820   INFO  Test to get the VFE params2024-03-08 08:38:19\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './cfgs/kitti_models/pointpillar_copy.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# common_utils.set_random_seed(66)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest to get the VFE params\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m time\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m, time\u001b[38;5;241m.\u001b[39mlocaltime(time\u001b[38;5;241m.\u001b[39mtime())))\n\u001b[0;32m---> 10\u001b[0m \u001b[43mcfg_from_yaml_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m demo_dataset \u001b[38;5;241m=\u001b[39m demo\u001b[38;5;241m.\u001b[39mDemoDataset(\n\u001b[1;32m     14\u001b[0m     dataset_cfg\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mDATA_CONFIG, class_names\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mCLASS_NAMES, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     15\u001b[0m     root_path\u001b[38;5;241m=\u001b[39mPath(data_path), ext\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.bin\u001b[39m\u001b[38;5;124m'\u001b[39m, logger\u001b[38;5;241m=\u001b[39mlogger\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     18\u001b[0m model \u001b[38;5;241m=\u001b[39m build_network(model_cfg\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mMODEL, num_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(cfg\u001b[38;5;241m.\u001b[39mCLASS_NAMES), dataset\u001b[38;5;241m=\u001b[39mdemo_dataset)\n",
      "File \u001b[0;32m~/OpenPCDet/pcdet/config.py:72\u001b[0m, in \u001b[0;36mcfg_from_yaml_file\u001b[0;34m(cfg_file, config)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcfg_from_yaml_file\u001b[39m(cfg_file, config):\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m             new_config \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39msafe_load(f, Loader\u001b[38;5;241m=\u001b[39myaml\u001b[38;5;241m.\u001b[39mFullLoader)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './cfgs/kitti_models/pointpillar_copy.yaml'"
     ]
    }
   ],
   "source": [
    "ckpt_path = './../output/kitti_models/pointpillar_copy/D_S2/ckpt/checkpoint_epoch_160.pth'\n",
    "cfg_path = './cfgs/kitti_models/pointpillar_copy.yaml'\n",
    "data_path = '/home/jiazx_ug/OpenPCDet/data/kitti/testing/velodyne/228931.bin'\n",
    "txt_path = '/home/jiazx_ug/OpenPCDet/data/kitti/testing/label_2/228931.txt'\n",
    "\n",
    "\n",
    "logger = common_utils.create_logger()   # logger.info('xxx')\n",
    "# common_utils.set_random_seed(66)\n",
    "logger.info('Test to get the VFE params' + time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "cfg_from_yaml_file(cfg_path, cfg)\n",
    "\n",
    "\n",
    "demo_dataset = demo.DemoDataset(\n",
    "    dataset_cfg=cfg.DATA_CONFIG, class_names=cfg.CLASS_NAMES, training=False,\n",
    "    root_path=Path(data_path), ext='.bin', logger=logger\n",
    ")\n",
    "\n",
    "model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), dataset=demo_dataset)\n",
    "model.load_params_from_file(filename=ckpt_path, logger=logger, to_cpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import kornia\n",
    "\n",
    "voxel_size = torch.tensor([0.16, 0.16, 4])\n",
    "pc_range = torch.tensor([-69.12, -39.68, -3., 69.12, 39.68, 1.])\n",
    "\n",
    "def trans_data_2_tensor(batch_dict):\n",
    "    for key, val in batch_dict.items():\n",
    "        if key == 'camera_imgs':\n",
    "            batch_dict[key] = val.cuda()\n",
    "        elif not isinstance(val, np.ndarray):\n",
    "            continue\n",
    "        elif key in ['frame_id', 'metadata', 'calib', 'image_paths','ori_shape','img_process_infos']:\n",
    "            continue\n",
    "        elif key in ['images']:\n",
    "            batch_dict[key] = kornia.image_to_tensor(val).float()\n",
    "        elif key in ['image_shape']:\n",
    "            batch_dict[key] = torch.from_numpy(val).int()\n",
    "        else:\n",
    "            batch_dict[key] = torch.from_numpy(val).float()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, data_dict in enumerate(demo_dataset):\n",
    "        data_dict = demo_dataset.collate_batch([data_dict])\n",
    "        trans_data_2_tensor(data_dict)\n",
    "\n",
    "model_cfg = model.model_cfg\n",
    "print(model_cfg)\n",
    "num_point_features = model_cfg.VFE.NUM_FILTERS\n",
    "num_point_features = 4\n",
    "\n",
    "in_channels = 10\n",
    "out_channels = 64\n",
    "use_norm = True\n",
    "last_layer = True\n",
    "grid_size = [(pc_range[3] - pc_range[0]) / voxel_size[0], (pc_range[4] - pc_range[1]) / voxel_size[1], 1]\n",
    "grid_size = torch.tensor(grid_size).int()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class isPointInQuadrangle(object):\n",
    "\n",
    "    def __int__(self):\n",
    "        self.__isInQuadrangleFlag = False\n",
    "\n",
    "    def cross_product(self, xp, yp, x1, y1, x2, y2):\n",
    "        return (x2 - x1) * (yp - y1)-(y2 - y1) * (xp - x1)\n",
    "\n",
    "    def compute_para(self, xp, yp, xa, ya, xb, yb, xc, yc, xd, yd):\n",
    "        cross_product_ab = isPointInQuadrangle().cross_product(xp, yp, xa, ya, xb, yb)\n",
    "        cross_product_bc = isPointInQuadrangle().cross_product(xp, yp, xb, yb, xc, yc)\n",
    "        cross_product_cd = isPointInQuadrangle().cross_product(xp, yp, xc, yc, xd, yd)\n",
    "        cross_product_da = isPointInQuadrangle().cross_product(xp, yp, xd, yd, xa, ya)\n",
    "        return cross_product_ab,cross_product_bc,cross_product_cd,cross_product_da\n",
    "\n",
    "    def is_in_rect(self, aa, bb, cc, dd):\n",
    "        if (aa > 0 and bb > 0 and cc > 0 and dd > 0) or (aa < 0 and bb < 0 and cc < 0 and dd < 0):\n",
    "            self.__isInQuadrangleFlag= True\n",
    "        else:\n",
    "            self.__isInQuadrangleFlag = False\n",
    "\n",
    "        return self.__isInQuadrangleFlag\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    aa, bb, cc, dd = isPointInQuadrangle().compute_para(600, 550, 508, 451, 730, 470, 718, 615, 495, 596)\n",
    "    print(isPointInQuadrangle().is_in_rect(aa, bb, cc, dd))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pillarVFE = VFE.PillarVFE(model_cfg=model_cfg.VFE, num_point_features=num_point_features, voxel_size=voxel_size, point_cloud_range=pc_range)\n",
    "pillarVFE.forward(data_dict)\n",
    "\n",
    "pillarScatter = Scatter.PointPillarScatter(model_cfg=model_cfg.MAP_TO_BEV, grid_size=grid_size)\n",
    "pillarScatter.forward(data_dict)\n",
    "\n",
    "print('Done,',data_dict['spatial_features'].shape)\n",
    "print(data_dict['voxel_coords'])\n",
    "\n",
    "sum_all_pillar_features = torch.sum(data_dict['pillar_features'], dim=0)\n",
    "sumsum_pillar_features = torch.sum(sum_all_pillar_features, dim=0)\n",
    "print(sumsum_pillar_features)\n",
    "\n",
    "sum_spatial_features = torch.sum(data_dict['spatial_features'])\n",
    "print(sum_spatial_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read txt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import open3d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pcd_path = '/home/ghosnp/dataset/mini_kitti/velodyne/training/velodyne/000011.bin'\n",
    "# txt_path = '/home/ghosnp/dataset/mini_kitti/label_2/training/label_2/000011.txt'\n",
    "POINT_CLOUD_RANGE = np.array([-69.12, -39.68, -3, 69.12, 39.68, 1], dtype=np.float32)\n",
    "\n",
    "with open(txt_path, 'r') as f:\n",
    "    txt = f.readlines()\n",
    "\n",
    "pcd = np.fromfile(data_path, dtype=np.float32).reshape(-1, 4)\n",
    "corners_bevs = []\n",
    "corners_3Ds = []\n",
    "\n",
    "\n",
    "\n",
    "for line in txt:\n",
    "    line = line.split()\n",
    "    lab, x, y, z, w, l, h, rot = line[0], line[11], line[12], line[13], line[9], line[10], line[8], line[14]\n",
    "    h, w, l, x, y, z, rot = map(float, [h, w, l, x, y, z, rot])\n",
    "    \n",
    "    if lab != 'DontCare':\n",
    "        x_corners = [l / 2, l / 2, -l / 2, -l / 2, l / 2, l / 2, -l / 2, -l / 2]\n",
    "        y_corners = [0, 0, 0, 0, -h, -h, -h, -h]\n",
    "        z_corners = [w / 2, -w / 2, -w / 2, w / 2, w / 2, -w / 2, -w / 2, w / 2]\n",
    "        corners_3d = np.vstack([x_corners, y_corners, z_corners])  # (3, 8)\n",
    "\n",
    "        # transform the 3d bbox from object coordiante to camera_0 coordinate\n",
    "        R = np.array([[np.cos(rot), 0, np.sin(rot)],\n",
    "                    [0, 1, 0],\n",
    "                    [-np.sin(rot), 0, np.cos(rot)]])\n",
    "   \n",
    "        corners_3d = np.dot(R, corners_3d).T + np.array([x, y, z])\n",
    "\n",
    "        # transform the 3d bbox from camera_0 coordinate to velodyne coordinate\n",
    "        corners_3d = corners_3d[:, [2, 0, 1]] * np.array([[1, -1, -1]])\n",
    "        corners_3Ds.append(corners_3d)\n",
    "        corners_bevs.append(corners_3d[:4, [0, 1]])\n",
    "        \n",
    "corners_bevs = np.array(corners_bevs)\n",
    "\n",
    "# corners_bevs add range offset\n",
    "corners_bevs[:, :, 0] += POINT_CLOUD_RANGE[3]\n",
    "corners_bevs[:, :, 1] += POINT_CLOUD_RANGE[4]\n",
    "corners_bevs /= 0.16\n",
    "\n",
    "\n",
    "feature_idx = []\n",
    "tool = isPointInQuadrangle()\n",
    "# Get the index in the range of corners_bevs\n",
    "for corners in corners_bevs:\n",
    "\n",
    "    vector01 = corners[1] - corners[0]\n",
    "    vector03 = corners[3] - corners[0]\n",
    "    square_area = np.linalg.norm(vector01) * np.linalg.norm(vector03)\n",
    "    max_x, min_x, max_y, min_y = np.max(corners[:,0]), np.min(corners[:,0]), np.max(corners[:,1]), np.min(corners[:,1])\n",
    "    max_x, min_x, max_y, min_y = int(max_x), int(min_x), int(max_y), int(min_y)\n",
    "    # get x,y with (min_x < x < max_x and min_y < y < max_y)\n",
    "    x = np.arange(min_x, max_x)\n",
    "    y = np.arange(min_y, max_y)\n",
    "    print(x,y)\n",
    "    temp_add = []\n",
    "    for i in x:\n",
    "        for j in y:\n",
    "            a, b, c, d = tool.compute_para(i, j, corners[0][0], corners[0][1], corners[1][0], corners[1][1], corners[2][0], corners[2][1], corners[3][0], corners[3][1])\n",
    "            res = tool.is_in_rect(a, b, c, d)\n",
    "            if res:\n",
    "                feature_idx.append([i, j])\n",
    "                temp_add.append([i, j])\n",
    "    \n",
    "feature_idx = np.array(feature_idx)\n",
    "print(feature_idx)\n",
    "\n",
    "# visualize the block with feature_idx\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "for corners_bev in corners_bevs:\n",
    "    plt.plot(corners_bev[:,0], corners_bev[:,1], 'r-')\n",
    "plt.scatter(feature_idx[:,0], feature_idx[:,1], s=1)\n",
    "plt.xlim(0, 864)\n",
    "plt.ylim(0, 864)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the idx out of the range(496,864)\n",
    "feature_idx = feature_idx[feature_idx[:,0] < 496]\n",
    "feature_idx = feature_idx[feature_idx[:,1] < 864]\n",
    "\n",
    "spatial_features_cpu = data_dict['spatial_features'][0]\n",
    "valid_features_cpu = spatial_features_cpu[:, feature_idx[:,0], feature_idx[:,1]]\n",
    "sum_features_cpu = torch.sum(valid_features_cpu, dim=1)\n",
    "sumsum_features_cpu = torch.sum(sum_features_cpu, dim=0)\n",
    "mean_features_cpu = torch.mean(valid_features_cpu, dim=1)\n",
    "# valid_features_cpu = valid_features_cpu.numpy()\n",
    "# tensor.detach().numpy()\n",
    "valid_features_cpu = valid_features_cpu.detach().numpy().T\n",
    "print(valid_features_cpu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for name, param in model.named_parameters():\n",
    "    # print(name, param.shape)\n",
    "    if name == 'vfe.pfn_layers.0.linear.weight':\n",
    "        vfe_pfn_weight = param.detach().cpu().numpy()\n",
    "    elif name == 'vfe.pfn_layers.0.norm.weight':\n",
    "        vfe_pfn_norm_weight = param.detach().cpu().numpy()\n",
    "    elif name == 'vfe.pfn_layers.0.norm.bias':\n",
    "        vfe_pfn_norm_bias = param.detach().cpu().numpy()\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print(vfe_pfn_norm_weight.shape, mean_features_cpu.shape)\n",
    "print(vfe_pfn_weight.shape)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "det_cu117",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
