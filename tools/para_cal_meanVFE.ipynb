{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import demo\n",
    "from pathlib import Path\n",
    "from pcdet.utils import common_utils\n",
    "from pcdet.config import cfg, cfg_from_yaml_file\n",
    "from pcdet.models import build_network, load_data_to_gpu\n",
    "import pcdet.datasets.processor.data_processor as DP\n",
    "import pcdet.datasets.dataset as D\n",
    "\n",
    "\n",
    "ckpt_path = './../output/kitti_models/voxel_rcnn_car/A_S22/ckpt/checkpoint_epoch_160.pth'\n",
    "cfg_path = './cfgs/kitti_models/voxel_rcnn_car.yaml'\n",
    "dataset_cfg = './cfgs/dataset_configs/kitti_dataset_copy.yaml'\n",
    "data_path = '/home/jiazx_ug/dataset/S2/A/training/velodyne/128976.bin'\n",
    "#data_path ='/home/jiazx_ug/dataset/S4/temp/training/snow_01.bin'\n",
    "txt_path = '/home/jiazx_ug/dataset/S2/A/training/label_2/128976.txt'\n",
    "data_dir_path = '/home/jiazx_ug/dataset/S4/temp/training/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the parameter in the config file, voxelize the point cloud\n",
    "\n",
    "# 1. load parameters\n",
    "logger = common_utils.create_logger() \n",
    "cfg_from_yaml_file(cfg_path, cfg)\n",
    "cfg_from_yaml_file(dataset_cfg, cfg.DATA_CONFIG)\n",
    "\n",
    "class_names = cfg.CLASS_NAMES\n",
    "point_cloud_range = cfg.DATA_CONFIG.POINT_CLOUD_RANGE\n",
    "training = False\n",
    "num_point_features = cfg.DATA_CONFIG.DATA_AUGMENTOR.AUG_CONFIG_LIST[0].NUM_POINT_FEATURES\n",
    "dataset_processor_cfg = cfg.DATA_CONFIG.DATA_PROCESSOR\n",
    "voxel_size = dataset_processor_cfg[2].VOXEL_SIZE\n",
    "max_number_per_voxel = dataset_processor_cfg[2].MAX_POINTS_PER_VOXEL\n",
    "points_range = cfg.DATA_CONFIG.POINT_CLOUD_RANGE\n",
    "\n",
    "\n",
    "# demo_dataset = demo.DemoDataset(\n",
    "#     dataset_cfg=cfg.DATA_CONFIG, class_names=cfg.CLASS_NAMES, training=False,\n",
    "#     root_path=Path(data_path), ext='.bin', logger=logger\n",
    "# )\n",
    "\n",
    "# model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), dataset=demo_dataset)\n",
    "# model.load_params_from_file(filename=ckpt_path, logger=logger, to_cpu=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (backbone_3d): VoxelBackBone8x(\n",
    "#       (conv_input): SparseSequential(\n",
    "#         (0): SubMConv3d(4, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
    "#         (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
    "#         (2): ReLU()\n",
    "#       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (513930956.py, line 86)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 86\u001b[0;36m\u001b[0m\n\u001b[0;31m    sub_points =\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage import transform\n",
    "from pcdet.models.backbones_3d.spconv_backbone_focal import VoxelBackBone8xFocal\n",
    "import torch\n",
    "import torchvision\n",
    "import spconv\n",
    "tv = None\n",
    "try:\n",
    "    import cumm.tensorview as tv\n",
    "except:\n",
    "    pass\n",
    "class voxelgenerator():\n",
    "    def __init__(self,vsize_xyz, coors_range_xyz, num_point_features, max_num_points_per_voxel, max_num_voxels):\n",
    "        print(vsize_xyz, coors_range_xyz, num_point_features, max_num_points_per_voxel, max_num_voxels)\n",
    "        try:\n",
    "            from spconv.utils import VoxelGeneratorV2 as VoxelGenerator\n",
    "            self.spconv_ver = 1\n",
    "        except:\n",
    "            try:\n",
    "                from spconv.utils import VoxelGenerator\n",
    "                self.spconv_ver = 1\n",
    "            except:\n",
    "                from spconv.utils import Point2VoxelCPU3d as VoxelGenerator\n",
    "                self.spconv_ver = 2\n",
    "\n",
    "        if self.spconv_ver == 1:\n",
    "            self._voxel_generator = VoxelGenerator(\n",
    "                voxel_size=vsize_xyz,\n",
    "                point_cloud_range=coors_range_xyz,\n",
    "                max_num_points=max_num_points_per_voxel,\n",
    "                max_voxels=max_num_voxels\n",
    "            )\n",
    "        else:\n",
    "            self._voxel_generator = VoxelGenerator(\n",
    "                vsize_xyz=vsize_xyz,\n",
    "                coors_range_xyz=coors_range_xyz,\n",
    "                num_point_features=num_point_features,\n",
    "                max_num_points_per_voxel=max_num_points_per_voxel,\n",
    "                max_num_voxels=max_num_voxels\n",
    "            )\n",
    "\n",
    "    def generate(self, points):\n",
    "        if self.spconv_ver == 1:\n",
    "            voxel_output = self._voxel_generator.generate(points)\n",
    "            if isinstance(voxel_output, dict):\n",
    "                voxels, coordinates, num_points = \\\n",
    "                    voxel_output['voxels'], voxel_output['coordinates'], voxel_output['num_points_per_voxel']\n",
    "            else:\n",
    "                voxels, coordinates, num_points = voxel_output\n",
    "        else:\n",
    "            assert tv is not None, f\"Unexpected error, library: 'cumm' wasn't imported properly.\"\n",
    "            voxel_output = self._voxel_generator.point_to_voxel(tv.from_numpy(points))\n",
    "            tv_voxels, tv_coordinates, tv_num_points = voxel_output\n",
    "            # make copy with numpy(), since numpy_view() will disappear as soon as the generator is deleted\n",
    "            voxels = tv_voxels.numpy()\n",
    "            coordinates = tv_coordinates.numpy()\n",
    "            num_points = tv_num_points.numpy()\n",
    "        return voxels, coordinates, num_points\n",
    "    \n",
    "    def meanVFE(self,voxel_features, voxel_num_points):\n",
    "        points_mean = voxel_features[:, :, :].sum(dim=1, keepdim=False) # Use sum() instead of _sum()\n",
    "        normalizer = torch.clamp_min(voxel_num_points.view(-1, 1), min=1.0).type_as(voxel_features)\n",
    "        points_mean = points_mean / normalizer #求出每个体素内 sum / 点数\n",
    "        return points_mean.contiguous()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "voxel_size = dataset_processor_cfg[2].VOXEL_SIZE\n",
    "points_range = cfg.DATA_CONFIG.POINT_CLOUD_RANGE\n",
    "num_point_features = cfg.DATA_CONFIG.DATA_AUGMENTOR.AUG_CONFIG_LIST[0].NUM_POINT_FEATURES\n",
    "max_number_per_voxel = dataset_processor_cfg[2].MAX_POINTS_PER_VOXEL\n",
    "max_number_of_voxels = dataset_processor_cfg[2].MAX_NUMBER_OF_VOXELS['train']\n",
    "#grid_size = cfg.MODEL.ROI_HEAD.ROI_GRID_POOL.GRID_SIZE\n",
    "\n",
    "grid_size = points_range[3:6] - points_range[0:3] / np.array(voxel_size)\n",
    "grid_size = np.round(grid_size).astype(np.int64)\n",
    "print(grid_size)\n",
    "\n",
    "\n",
    "voxel_generator = voxelgenerator(voxel_size, points_range, num_point_features, max_number_per_voxel, max_number_of_voxels)\n",
    "points = np.fromfile(data_path, dtype=np.float32).reshape(-1, 4)\n",
    "# only use the points in points range\n",
    "\n",
    "\n",
    "\n",
    "voxels, coordinates, num_points = voxel_generator.generate(points)\n",
    "\n",
    "voxels = torch.from_numpy(voxels)\n",
    "coordinates = torch.from_numpy(coordinates)\n",
    "num_points = torch.from_numpy(num_points)\n",
    "\n",
    "# print max of coordinates\n",
    "print(coordinates.max(0), coordinates.min(0))\n",
    "\n",
    "mean_voxel = voxel_generator.meanVFE(voxels, num_points)\n",
    "print(mean_voxel.shape, coordinates.shape, num_points.shape)\n",
    "\n",
    "\n",
    "# 2. load the voxelbackbone\n",
    "backbone = VoxelBackBone8xFocal(model_cfg=cfg, input_channels=num_point_features, grid_size=grid_size)\n",
    "# [batch_idx, z_idx, y_idx, x_idx]\n",
    "coordinates = torch.cat([torch.zeros_like(coordinates[:, :1]), coordinates], dim=1)\n",
    "for i in range(len(coordinates)):\n",
    "    coordinates[i, 0] = i\n",
    "\n",
    "# mean_voxels, coordinates, num_points to cuda\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "torch.cuda.set_device(0)\n",
    "mean_voxel = mean_voxel.to(0)\n",
    "coordinates = coordinates.to(0)\n",
    "num_points = num_points.to(0)\n",
    "\n",
    "sp_input_res = backbone.get_input_layer_result(voxel_features=mean_voxel, voxel_coords=coordinates,batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.9411, 0.0000,  ..., 0.0000, 1.0799, 0.1477],\n",
       "        [0.0000, 0.9206, 0.0000,  ..., 0.0000, 1.0669, 0.1567],\n",
       "        [0.0000, 0.9191, 0.0000,  ..., 0.0000, 1.0682, 0.1608],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.1426,  ..., 0.0000, 0.6553, 1.2706],\n",
       "        [0.0000, 0.0000, 0.1537,  ..., 0.0000, 0.6447, 1.2692],\n",
       "        [0.0000, 0.0000, 0.1563,  ..., 0.0000, 0.6409, 1.2665]],\n",
       "       device='cuda:0', grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_input_res.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据sp_input_res.indices(batch_id,z,y,x)生成索引三维数组，填充为该位置的batch_id\n",
    "sp_cpu = sp_input_res.features.cpu().detach().numpy()\n",
    "\n",
    "indices = sp_input_res.indices.int().cpu().numpy()\n",
    "indices_3d = np.zeros(grid_size, dtype=np.int32)\n",
    "\n",
    "ind_temp = indices.copy()\n",
    "# 不确定这里是否正确\n",
    "ind_temp[:, 1:] = ind_temp[:, 1:] / 2\n",
    "ind_temp = ind_temp.astype(np.int32)\n",
    "indices_3d[ind_temp[:, 3], ind_temp[:, 2], ind_temp[:, 1]] = ind_temp[:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N, C, D, H, W = spatial_features.shape\n",
    "# spatial_features = spatial_features.view(N, C * D, H, W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # spatial_features = spatial_features.cpu().detach().numpy()\n",
    "# print(spatial_features.shape)\n",
    "# print(grid_size)\n",
    "\n",
    "# for i in range(512):\n",
    "#     print(spatial_features[0, i, :, :])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "det_cu117",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
