{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import open3d\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import demo as demo\n",
    "\n",
    "from pcdet.config import cfg, cfg_from_yaml_file\n",
    "from pcdet.datasets import DatasetTemplate\n",
    "from pcdet.models import build_network, load_data_to_gpu\n",
    "from pcdet.utils import common_utils\n",
    "\n",
    "\n",
    "# 3 tool class, PillarVFE, PFNLayer, PointPillarScatter\n",
    "from pcdet.models.backbones_3d.vfe import pillar_vfe as VFE\n",
    "from pcdet.models.backbones_2d.map_to_bev import pointpillar_scatter as Scatter\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "torch.cuda.set_device(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-08 10:15:31,041   INFO  Test to get the VFE params2024-03-08 10:15:31\n",
      "2024-03-08 10:15:31,041   INFO  Test to get the VFE params2024-03-08 10:15:31\n",
      "2024-03-08 10:15:31,041   INFO  Test to get the VFE params2024-03-08 10:15:31\n",
      "2024-03-08 10:15:31,041   INFO  Test to get the VFE params2024-03-08 10:15:31\n",
      "2024-03-08 10:15:31,159   INFO  ==> Loading parameters from checkpoint ./../output/kitti_models/pointpillar_copy/D_S2/ckpt/checkpoint_epoch_160.pth to CPU\n",
      "2024-03-08 10:15:31,159   INFO  ==> Loading parameters from checkpoint ./../output/kitti_models/pointpillar_copy/D_S2/ckpt/checkpoint_epoch_160.pth to CPU\n",
      "2024-03-08 10:15:31,159   INFO  ==> Loading parameters from checkpoint ./../output/kitti_models/pointpillar_copy/D_S2/ckpt/checkpoint_epoch_160.pth to CPU\n",
      "2024-03-08 10:15:31,159   INFO  ==> Loading parameters from checkpoint ./../output/kitti_models/pointpillar_copy/D_S2/ckpt/checkpoint_epoch_160.pth to CPU\n",
      "2024-03-08 10:15:31,199   INFO  ==> Checkpoint trained from version: pcdet+0.6.0+255db8f\n",
      "2024-03-08 10:15:31,199   INFO  ==> Checkpoint trained from version: pcdet+0.6.0+255db8f\n",
      "2024-03-08 10:15:31,199   INFO  ==> Checkpoint trained from version: pcdet+0.6.0+255db8f\n",
      "2024-03-08 10:15:31,199   INFO  ==> Checkpoint trained from version: pcdet+0.6.0+255db8f\n",
      "2024-03-08 10:15:31,283   INFO  ==> Done (loaded 127/127)\n",
      "2024-03-08 10:15:31,283   INFO  ==> Done (loaded 127/127)\n",
      "2024-03-08 10:15:31,283   INFO  ==> Done (loaded 127/127)\n",
      "2024-03-08 10:15:31,283   INFO  ==> Done (loaded 127/127)\n"
     ]
    }
   ],
   "source": [
    "ckpt_path = './../output/kitti_models/pointpillar_copy/D_S2/ckpt/checkpoint_epoch_160.pth'\n",
    "cfg_path = './cfgs/kitti_models/pointpillar_copy.yaml'\n",
    "data_path = '/home/jiazx_ug/dataset/S2/A/training/velodyne/128976.bin'\n",
    "txt_path = '/home/jiazx_ug/dataset/S2/A/training/label_2/128976.txt'\n",
    "\n",
    "\n",
    "logger = common_utils.create_logger()   # logger.info('xxx')\n",
    "# common_utils.set_random_seed(66)\n",
    "logger.info('Test to get the VFE params' + time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "cfg_from_yaml_file(cfg_path, cfg)\n",
    "\n",
    "\n",
    "demo_dataset = demo.DemoDataset(\n",
    "    dataset_cfg=cfg.DATA_CONFIG, class_names=cfg.CLASS_NAMES, training=False,\n",
    "    root_path=Path(data_path), ext='.bin', logger=logger\n",
    ")\n",
    "\n",
    "model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), dataset=demo_dataset)\n",
    "model.load_params_from_file(filename=ckpt_path, logger=logger, to_cpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NAME': 'PointPillar', 'VFE': {'NAME': 'PillarVFE', 'WITH_DISTANCE': False, 'USE_ABSLOTE_XYZ': True, 'USE_NORM': True, 'NUM_FILTERS': [64]}, 'MAP_TO_BEV': {'NAME': 'PointPillarScatter', 'NUM_BEV_FEATURES': 64}, 'BACKBONE_2D': {'NAME': 'BaseBEVBackbone', 'LAYER_NUMS': [3, 5, 5], 'LAYER_STRIDES': [2, 2, 2], 'NUM_FILTERS': [64, 128, 256], 'UPSAMPLE_STRIDES': [1, 2, 4], 'NUM_UPSAMPLE_FILTERS': [128, 128, 128]}, 'DENSE_HEAD': {'NAME': 'AnchorHeadSingle', 'CLASS_AGNOSTIC': False, 'USE_DIRECTION_CLASSIFIER': True, 'DIR_OFFSET': 0.78539, 'DIR_LIMIT_OFFSET': 0.0, 'NUM_DIR_BINS': 2, 'ANCHOR_GENERATOR_CONFIG': [{'class_name': 'Car', 'anchor_sizes': [[3.9, 1.6, 1.56]], 'anchor_rotations': [0, 1.57], 'anchor_bottom_heights': [-1.78], 'align_center': False, 'feature_map_stride': 2, 'matched_threshold': 0.6, 'unmatched_threshold': 0.45}, {'class_name': 'Pedestrian', 'anchor_sizes': [[0.8, 0.6, 1.73]], 'anchor_rotations': [0, 1.57], 'anchor_bottom_heights': [-0.6], 'align_center': False, 'feature_map_stride': 2, 'matched_threshold': 0.5, 'unmatched_threshold': 0.35}, {'class_name': 'Rider', 'anchor_sizes': [[1.76, 0.6, 1.73]], 'anchor_rotations': [0, 1.57], 'anchor_bottom_heights': [-0.6], 'align_center': False, 'feature_map_stride': 2, 'matched_threshold': 0.5, 'unmatched_threshold': 0.35}, {'class_name': 'Truck', 'anchor_sizes': [[3.9, 1.6, 1.56]], 'anchor_rotations': [0, 1.57], 'anchor_bottom_heights': [-1.78], 'align_center': False, 'feature_map_stride': 2, 'matched_threshold': 0.6, 'unmatched_threshold': 0.45}, {'class_name': 'Van', 'anchor_sizes': [[3.9, 1.6, 1.56]], 'anchor_rotations': [0, 1.57], 'anchor_bottom_heights': [-1.78], 'align_center': False, 'feature_map_stride': 2, 'matched_threshold': 0.6, 'unmatched_threshold': 0.45}], 'TARGET_ASSIGNER_CONFIG': {'NAME': 'AxisAlignedTargetAssigner', 'POS_FRACTION': -1.0, 'SAMPLE_SIZE': 512, 'NORM_BY_NUM_EXAMPLES': False, 'MATCH_HEIGHT': False, 'BOX_CODER': 'ResidualCoder'}, 'LOSS_CONFIG': {'LOSS_WEIGHTS': {'cls_weight': 1.0, 'loc_weight': 2.0, 'dir_weight': 0.2, 'code_weights': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}}, 'POST_PROCESSING': {'RECALL_THRESH_LIST': [0.3, 0.5, 0.7], 'SCORE_THRESH': 0.1, 'OUTPUT_RAW_SCORE': False, 'EVAL_METRIC': 'kitti', 'NMS_CONFIG': {'MULTI_CLASSES_NMS': False, 'NMS_TYPE': 'nms_gpu', 'NMS_THRESH': 0.01, 'NMS_PRE_MAXSIZE': 4096, 'NMS_POST_MAXSIZE': 500}}}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import kornia\n",
    "\n",
    "voxel_size = torch.tensor([0.16, 0.16, 4])\n",
    "pc_range = torch.tensor([-69.12, -39.68, -3., 69.12, 39.68, 1.])\n",
    "\n",
    "def trans_data_2_tensor(batch_dict):\n",
    "    for key, val in batch_dict.items():\n",
    "        if key == 'camera_imgs':\n",
    "            batch_dict[key] = val.cuda()\n",
    "        elif not isinstance(val, np.ndarray):\n",
    "            continue\n",
    "        elif key in ['frame_id', 'metadata', 'calib', 'image_paths','ori_shape','img_process_infos']:\n",
    "            continue\n",
    "        elif key in ['images']:\n",
    "            batch_dict[key] = kornia.image_to_tensor(val).float()\n",
    "        elif key in ['image_shape']:\n",
    "            batch_dict[key] = torch.from_numpy(val).int()\n",
    "        else:\n",
    "            batch_dict[key] = torch.from_numpy(val).float()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, data_dict in enumerate(demo_dataset):\n",
    "        data_dict = demo_dataset.collate_batch([data_dict])\n",
    "        trans_data_2_tensor(data_dict)\n",
    "\n",
    "model_cfg = model.model_cfg\n",
    "print(model_cfg)\n",
    "num_point_features = model_cfg.VFE.NUM_FILTERS\n",
    "num_point_features = 4\n",
    "\n",
    "in_channels = 10\n",
    "out_channels = 64\n",
    "use_norm = True\n",
    "last_layer = True\n",
    "grid_size = [(pc_range[3] - pc_range[0]) / voxel_size[0], (pc_range[4] - pc_range[1]) / voxel_size[1], 1]\n",
    "grid_size = torch.tensor(grid_size).int()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class isPointInQuadrangle(object):\n",
    "\n",
    "    def __int__(self):\n",
    "        self.__isInQuadrangleFlag = False\n",
    "\n",
    "    def cross_product(self, xp, yp, x1, y1, x2, y2):\n",
    "        return (x2 - x1) * (yp - y1)-(y2 - y1) * (xp - x1)\n",
    "\n",
    "    def compute_para(self, xp, yp, xa, ya, xb, yb, xc, yc, xd, yd):\n",
    "        cross_product_ab = isPointInQuadrangle().cross_product(xp, yp, xa, ya, xb, yb)\n",
    "        cross_product_bc = isPointInQuadrangle().cross_product(xp, yp, xb, yb, xc, yc)\n",
    "        cross_product_cd = isPointInQuadrangle().cross_product(xp, yp, xc, yc, xd, yd)\n",
    "        cross_product_da = isPointInQuadrangle().cross_product(xp, yp, xd, yd, xa, ya)\n",
    "        return cross_product_ab,cross_product_bc,cross_product_cd,cross_product_da\n",
    "\n",
    "    def is_in_rect(self, aa, bb, cc, dd):\n",
    "        if (aa > 0 and bb > 0 and cc > 0 and dd > 0) or (aa < 0 and bb < 0 and cc < 0 and dd < 0):\n",
    "            self.__isInQuadrangleFlag= True\n",
    "        else:\n",
    "            self.__isInQuadrangleFlag = False\n",
    "\n",
    "        return self.__isInQuadrangleFlag\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    aa, bb, cc, dd = isPointInQuadrangle().compute_para(600, 550, 508, 451, 730, 470, 718, 615, 495, 596)\n",
    "    print(isPointInQuadrangle().is_in_rect(aa, bb, cc, dd))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, torch.Size([1, 64, 496, 864])\n",
      "tensor([[  0.,   0., 324., 283.],\n",
      "        [  0.,   0., 324., 286.],\n",
      "        [  0.,   0., 325., 287.],\n",
      "        ...,\n",
      "        [  0.,   0., 241., 400.],\n",
      "        [  0.,   0., 242., 400.],\n",
      "        [  0.,   0., 243., 400.]])\n",
      "tensor(2726444.7500, grad_fn=<SumBackward1>)\n",
      "tensor(2726444.7500, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pillarVFE = VFE.PillarVFE(model_cfg=model_cfg.VFE, num_point_features=num_point_features, voxel_size=voxel_size, point_cloud_range=pc_range)\n",
    "pillarVFE.forward(data_dict)\n",
    "\n",
    "pillarScatter = Scatter.PointPillarScatter(model_cfg=model_cfg.MAP_TO_BEV, grid_size=grid_size)\n",
    "pillarScatter.forward(data_dict)\n",
    "\n",
    "print('Done,',data_dict['spatial_features'].shape)\n",
    "print(data_dict['voxel_coords'])\n",
    "\n",
    "sum_all_pillar_features = torch.sum(data_dict['pillar_features'], dim=0)\n",
    "sumsum_pillar_features = torch.sum(sum_all_pillar_features, dim=0)\n",
    "print(sumsum_pillar_features)\n",
    "\n",
    "sum_spatial_features = torch.sum(data_dict['spatial_features'])\n",
    "print(sum_spatial_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[358 359 360 361 362 363 364 365 366 367 368 369] [122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139\n",
      " 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157\n",
      " 158]\n",
      "[-24 -23 -22 -21 -20 -19 -18 -17 -16 -15 -14 -13 -12 -11 -10  -9  -8  -7\n",
      "  -6  -5  -4  -3  -2] [242 243 244 245 246 247 248 249 250 251 252]\n",
      "[11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34\n",
      " 35 36 37 38 39 40 41 42 43 44] [220 221 222 223 224 225 226 227 228 229 230]\n",
      "[ 8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31\n",
      " 32 33 34 35 36 37 38 39 40 41 42 43 44] [263 264 265 266 267 268 269 270 271 272 273 274 275]\n",
      "[413 414] [-24 -23]\n",
      "[515 516] [314 315]\n",
      "[-19 -18 -17 -16 -15 -14 -13 -12 -11 -10] [289 290 291 292 293]\n",
      "[301 302 303 304 305 306 307 308 309] [655 656 657 658 659 660 661 662 663 664]\n",
      "[440 441 442 443 444 445 446 447 448 449 450 451 452] [267 268 269 270 271]\n",
      "[[359 123]\n",
      " [359 124]\n",
      " [359 125]\n",
      " ...\n",
      " [452 269]\n",
      " [452 270]\n",
      " [452 271]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read txt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import open3d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pcd_path = '/home/ghosnp/dataset/mini_kitti/velodyne/training/velodyne/000011.bin'\n",
    "# txt_path = '/home/ghosnp/dataset/mini_kitti/label_2/training/label_2/000011.txt'\n",
    "POINT_CLOUD_RANGE = np.array([-69.12, -39.68, -3, 69.12, 39.68, 1], dtype=np.float32)\n",
    "\n",
    "with open(txt_path, 'r') as f:\n",
    "    txt = f.readlines()\n",
    "\n",
    "pcd = np.fromfile(data_path, dtype=np.float32).reshape(-1, 4)\n",
    "corners_bevs = []\n",
    "corners_3Ds = []\n",
    "\n",
    "\n",
    "\n",
    "for line in txt:\n",
    "    line = line.split()\n",
    "    lab, x, y, z, w, l, h, rot = line[0], line[11], line[12], line[13], line[9], line[10], line[8], line[14]\n",
    "    h, w, l, x, y, z, rot = map(float, [h, w, l, x, y, z, rot])\n",
    "    \n",
    "    if lab != 'DontCare':\n",
    "        x_corners = [l / 2, l / 2, -l / 2, -l / 2, l / 2, l / 2, -l / 2, -l / 2]\n",
    "        y_corners = [0, 0, 0, 0, -h, -h, -h, -h]\n",
    "        z_corners = [w / 2, -w / 2, -w / 2, w / 2, w / 2, -w / 2, -w / 2, w / 2]\n",
    "        corners_3d = np.vstack([x_corners, y_corners, z_corners])  # (3, 8)\n",
    "\n",
    "        # transform the 3d bbox from object coordiante to camera_0 coordinate\n",
    "        R = np.array([[np.cos(rot), 0, np.sin(rot)],\n",
    "                    [0, 1, 0],\n",
    "                    [-np.sin(rot), 0, np.cos(rot)]])\n",
    "   \n",
    "        corners_3d = np.dot(R, corners_3d).T + np.array([x, y, z])\n",
    "\n",
    "        # transform the 3d bbox from camera_0 coordinate to velodyne coordinate\n",
    "        corners_3d = corners_3d[:, [2, 0, 1]] * np.array([[1, -1, -1]])\n",
    "        corners_3Ds.append(corners_3d)\n",
    "        corners_bevs.append(corners_3d[:4, [0, 1]])\n",
    "        \n",
    "corners_bevs = np.array(corners_bevs)\n",
    "\n",
    "# corners_bevs add range offset\n",
    "corners_bevs[:, :, 0] += POINT_CLOUD_RANGE[3]\n",
    "corners_bevs[:, :, 1] += POINT_CLOUD_RANGE[4]\n",
    "corners_bevs /= 0.16\n",
    "\n",
    "\n",
    "feature_idx = []\n",
    "tool = isPointInQuadrangle()\n",
    "# Get the index in the range of corners_bevs\n",
    "for corners in corners_bevs:\n",
    "\n",
    "    vector01 = corners[1] - corners[0]\n",
    "    vector03 = corners[3] - corners[0]\n",
    "    square_area = np.linalg.norm(vector01) * np.linalg.norm(vector03)\n",
    "    max_x, min_x, max_y, min_y = np.max(corners[:,0]), np.min(corners[:,0]), np.max(corners[:,1]), np.min(corners[:,1])\n",
    "    max_x, min_x, max_y, min_y = int(max_x), int(min_x), int(max_y), int(min_y)\n",
    "    # get x,y with (min_x < x < max_x and min_y < y < max_y)\n",
    "    x = np.arange(min_x, max_x)\n",
    "    y = np.arange(min_y, max_y)\n",
    "    print(x,y)\n",
    "    temp_add = []\n",
    "    for i in x:\n",
    "        for j in y:\n",
    "            a, b, c, d = tool.compute_para(i, j, corners[0][0], corners[0][1], corners[1][0], corners[1][1], corners[2][0], corners[2][1], corners[3][0], corners[3][1])\n",
    "            res = tool.is_in_rect(a, b, c, d)\n",
    "            if res:\n",
    "                feature_idx.append([i, j])\n",
    "                temp_add.append([i, j])\n",
    "    \n",
    "feature_idx = np.array(feature_idx)\n",
    "print(feature_idx)\n",
    "\n",
    "# visualize the block with feature_idx\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "for corners_bev in corners_bevs:\n",
    "    plt.plot(corners_bev[:,0], corners_bev[:,1], 'r-')\n",
    "plt.scatter(feature_idx[:,0], feature_idx[:,1], s=1)\n",
    "plt.xlim(0, 864)\n",
    "plt.ylim(0, 864)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1525, 64)\n"
     ]
    }
   ],
   "source": [
    "# drop the idx out of the range(496,864)\n",
    "feature_idx = feature_idx[feature_idx[:,0] < 496]\n",
    "feature_idx = feature_idx[feature_idx[:,1] < 864]\n",
    "\n",
    "spatial_features_cpu = data_dict['spatial_features'][0]\n",
    "valid_features_cpu = spatial_features_cpu[:, feature_idx[:,0], feature_idx[:,1]]\n",
    "sum_features_cpu = torch.sum(valid_features_cpu, dim=1)\n",
    "sumsum_features_cpu = torch.sum(sum_features_cpu, dim=0)\n",
    "mean_features_cpu = torch.mean(valid_features_cpu, dim=1)\n",
    "# valid_features_cpu = valid_features_cpu.numpy()\n",
    "# tensor.detach().numpy()\n",
    "valid_features_cpu = valid_features_cpu.detach().numpy().T\n",
    "print(valid_features_cpu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_idx = feature_idx[feature_idx[:,0] < 496]\n",
    "# feature_idx = feature_idx[feature_idx[:,1] < 864]\n",
    "\n",
    "# # feature_idx load to gpu\n",
    "# feature_idx_gpu = torch.from_numpy(feature_idx).cuda()\n",
    "# # load the spatial_features, on gpu\n",
    "# spatial_features_gpu = data_dict['spatial_features'][0].cuda()\n",
    "# # spatial_features_gpu = data_dict['spatial_features'][0]\n",
    "# # get the feature with feature_idx\n",
    "# valid_features_gpu = spatial_features_gpu[:, feature_idx_gpu[:,1], feature_idx_gpu[:,0]]\n",
    "# # sum the features\n",
    "# sum_features_gpu = torch.sum(valid_features_gpu, dim=1)\n",
    "# sumsum_features_gpu = torch.sum(sum_features_gpu, dim=0)\n",
    "# print(sumsum_features_gpu)\n",
    "# # mean the features\n",
    "# mean_features_gpu = torch.mean(valid_features_gpu, dim=1)\n",
    "# mean_features = mean_features_gpu.detach().numpy()\n",
    "# valid_features = valid_features_gpu.detach().numpy().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,) torch.Size([64])\n",
      "(64, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for name, param in model.named_parameters():\n",
    "    # print(name, param.shape)\n",
    "    if name == 'vfe.pfn_layers.0.linear.weight':\n",
    "        vfe_pfn_weight = param.detach().cpu().numpy()\n",
    "    elif name == 'vfe.pfn_layers.0.norm.weight':\n",
    "        vfe_pfn_norm_weight = param.detach().cpu().numpy()\n",
    "    elif name == 'vfe.pfn_layers.0.norm.bias':\n",
    "        vfe_pfn_norm_bias = param.detach().cpu().numpy()\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print(vfe_pfn_norm_weight.shape, mean_features_cpu.shape)\n",
    "print(vfe_pfn_weight.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAND -0.022657316045839516 11.43917959255389\n",
      "MEAN 0.1927175521850586 10.184184\n"
     ]
    }
   ],
   "source": [
    "# calcuate the  Pearson correlation coefficient (PCC) of the features\n",
    "def cal_PCC(a,b):\n",
    "    # a,b are two vectors, both are numpy array(64,)\n",
    "    a_mean = np.mean(a)\n",
    "    b_mean = np.mean(b)\n",
    "    a_std = np.std(a)\n",
    "    b_std = np.std(b)\n",
    "    a = (a - a_mean) / a_std\n",
    "    b = (b - b_mean) / b_std\n",
    "\n",
    "    pcc = np.sum(a * b) / (64 - 1)\n",
    "    return pcc\n",
    "\n",
    "def cal_DIST(a,b):\n",
    "    # a,b are two vectors, both are numpy array(64,)\n",
    "    a_mean = np.mean(a)\n",
    "    b_mean = np.mean(b)\n",
    "    a_std = np.std(a)\n",
    "    b_std = np.std(b)\n",
    "    a = (a - a_mean) / a_std\n",
    "    b = (b - b_mean) / b_std\n",
    "\n",
    "    dist = np.sqrt(np.sum(np.square(a - b)))\n",
    "    return dist\n",
    "\n",
    "\n",
    "\n",
    "# random a 64 dim vector\n",
    "random_vector = np.random.rand(64)\n",
    "print('RAND',cal_PCC(random_vector, vfe_pfn_norm_weight), cal_DIST(random_vector, vfe_pfn_norm_weight))\n",
    "\n",
    "\n",
    "new_valid_features = []\n",
    "for i in range(valid_features_cpu.shape[0]):\n",
    "    if np.sum(valid_features_cpu[i]) != 0:\n",
    "        new_valid_features.append(valid_features_cpu[i])\n",
    "\n",
    "new_mean_features = np.mean(new_valid_features, axis=0)\n",
    "print('MEAN',cal_PCC(new_mean_features, vfe_pfn_norm_weight), cal_DIST(new_mean_features, vfe_pfn_norm_weight))\n",
    "\n",
    "pccs , dists = [], []\n",
    "\n",
    "for f in new_valid_features:\n",
    "    norm_f = (f - np.mean(f)) / np.std(f)\n",
    "    pcc = cal_PCC(norm_f, vfe_pfn_norm_weight)\n",
    "    dist = cal_DIST(norm_f, vfe_pfn_norm_weight)\n",
    "    pccs.append(pcc)\n",
    "    dists.append(dist)\n",
    "\n",
    "pillar_features = data_dict['pillar_features'].detach().cpu().numpy()\n",
    "\n",
    "pccs_a, dists_a = [], []\n",
    "for f in pillar_features:\n",
    "    norm_f = (f - np.mean(f)) / np.std(f)\n",
    "    pcc = cal_PCC(norm_f, vfe_pfn_norm_weight)\n",
    "    dist = cal_DIST(norm_f, vfe_pfn_norm_weight)\n",
    "    pccs_a.append(pcc)\n",
    "    dists_a.append(dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAILD\n",
      "PCC 0.19269155320667083 0.00015671873039988679\n",
      "DIST 10.184344 0.0009699762\n",
      "ALL\n",
      "PCC 0.01800390163164613 0.129577776886127\n",
      "DIST 11.188495 0.7410347\n"
     ]
    }
   ],
   "source": [
    "print('VAILD')\n",
    "print('PCC', np.mean(pccs), np.std(pccs))\n",
    "print('DIST', np.mean(dists), np.std(dists))\n",
    "\n",
    "print('ALL')\n",
    "print('PCC', np.mean(pccs_a), np.std(pccs_a))\n",
    "print('DIST', np.mean(dists_a), np.std(dists_a))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load data_dict['spatial_features'] to cpu\n",
    "# spatial_features = data_dict['spatial_features'].detach().cpu().numpy()\n",
    "# spatial_features = spatial_features[0]\n",
    "\n",
    "# feature_idx = feature_idx[feature_idx[:,0] < 496]\n",
    "# feature_idx = feature_idx[feature_idx[:,1] < 864]\n",
    "\n",
    "# valid_features = np.array(spatial_features[:,  feature_idx[:,1], feature_idx[:,0]])\n",
    "\n",
    "# # print(spatial_features.shape)\n",
    "\n",
    "\n",
    "# # valid_features = np.array(spatial_features[:, feature_idx[:,1], feature_idx[:,0]])\n",
    "\n",
    "# for name, param in model.named_parameters():\n",
    "#     # print(name, param.shape)\n",
    "#     if name == 'vfe.pfn_layers.0.linear.weight':\n",
    "#         vfe_pfn_weight = param.detach().cpu().numpy()\n",
    "#     elif name == 'vfe.pfn_layers.0.norm.weight':\n",
    "#         vfe_pfn_norm_weight = param.detach().cpu().numpy()\n",
    "#     elif name == 'vfe.pfn_layers.0.norm.bias':\n",
    "#         vfe_pfn_norm_bias = param.detach().cpu().numpy()\n",
    "#     else:\n",
    "#         pass\n",
    "# all_features = np.sum(spatial_features, axis=0)\n",
    "# print(\"[ALL]\")\n",
    "# print(all_features)\n",
    "\n",
    "\n",
    "# print(\"[MODEL]\")\n",
    "\n",
    "# print(vfe_pfn_norm_weight)\n",
    "\n",
    "# # print(\"[DATA]\")\n",
    "# # # print(valid_features)\n",
    "# # for f in valid_features:\n",
    "# #     print(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003513929565596339 0.007031162933601614\n",
      "0.13864819321059274 0.004965254633415277\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "\n",
    "X_train = vfe_pfn_weight.T\n",
    "X_test = valid_features_cpu\n",
    "clf = svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.05)\n",
    "clf.fit(X_train)\n",
    "\n",
    "distances = np.abs(clf.decision_function(X_test))\n",
    "print(np.mean(distances), np.std(distances))\n",
    "\n",
    "all_features = data_dict['pillar_features'].detach().cpu().numpy()\n",
    "distances = np.abs(clf.decision_function(all_features))\n",
    "print(np.mean(distances), np.std(distances))\n",
    "\n",
    "# DATA  -> MODEL\n",
    "# C-S2 -> C-S2\n",
    "# 0.019839489986762694 0.0450290048262891\n",
    "# 0.12566919739974516 0.004066661647355991\n",
    "\n",
    "# C-S2 -> B-S2\n",
    "# 0.02273767303443326 0.04526851864487868\n",
    "# 0.12930946103417057 0.003631496190221971\n",
    "\n",
    "# C-S2 -> A-S2\n",
    "# 0.023071117669783103 0.04811669151878394\n",
    "# 0.1376982921235265 0.000912575582206974\n",
    "\n",
    "# C-S2 -> D-S2\n",
    "# 0.02362505405749544 0.04893671651987857\n",
    "# 0.13929063141655862 0.003082539515942347"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "print(model.vfe.pfn_layers[0].linear.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25452,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw (distance-PCC), use matplotib.plt\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(6,5))\n",
    "print(distances.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pcdet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
